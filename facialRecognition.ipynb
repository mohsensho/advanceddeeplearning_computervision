{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Perform Facial Recognition with Deep Learning in Keras Using CNN\n",
    "Course-end Project 4\n",
    "\n",
    "DESCRIPTION\n",
    "\n",
    "Facial recognition is a biometric alternative that measures unique characteristics of a human face. Applications available today include flight check in, tagging friends and family members in photos, and “tailored” advertising. You are a computer vision engineer who needs to develop a face recognition programme with deep convolutional neural networks.\n",
    "\n",
    "Objective: Use a deep convolutional neural network to perform facial recognition using Keras.\n",
    "\n",
    "Dataset Details:\n",
    "ORL face database composed of 400 images of size 112 x 92. There are 40 people, 10 images per person. The images were taken at different times, lighting and facial expressions. The faces are in an upright position in frontal view, with a slight left-right rotation.\n",
    "\n",
    "Link to the Dataset: https://www.dropbox.com/s/i7uzp5yxk7wruva/ORL_faces.npz?dl=0\n",
    "\n",
    "Prerequisites:\n",
    "Keras\n",
    "Scikit Learn\n",
    "\n",
    "Steps to be followed:\n",
    "\n",
    "1.   Input the required libraries\n",
    "2.   Load the dataset after loading the dataset, you have to normalize every image.\n",
    "3.   Split the dataset\n",
    "4.   Transform the images to equal sizes to feed in CNN\n",
    "5.   Build a CNN model that has 3 main layers:\n",
    "     *    Convolutional Layer\n",
    "     *    Pooling Layer\n",
    "     *    Fully Connected Layer\n",
    "6.   Train the model\n",
    "7.   Plot the result\n",
    "8.   Iterate the model until the accuracy is above 90%\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step1: Input the required libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step2: Load the dataset after loading the dataset and have to normalize every image.\n",
    "#load dataset\n",
    "data = np.load('ORL_faces.npz') \n",
    "\n",
    "# load the \"Train Images\"\n",
    "x_train = data['trainX']\n",
    "#normalize every image\n",
    "x_train = np.array(x_train,dtype='float32')/255\n",
    "\n",
    "x_test = data['testX']\n",
    "x_test = np.array(x_test,dtype='float32')/255\n",
    "\n",
    "# load the Label of Images\n",
    "y_train= data['trainY']\n",
    "y_test= data['testY']\n",
    "\n",
    "# show the train and test Data format\n",
    "print('x_train : {}'.format(x_train[:]))\n",
    "print('Y-train shape: {}'.format(y_train))\n",
    "print('x_test shape: {}'.format(x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To See the images in Train and Test data.\n",
    "c=x_train[1].reshape(112,92)\n",
    "plt.imshow(c)\n",
    "plt.show()\n",
    "d=x_test[1].reshape(112,92)\n",
    "plt.imshow(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Split DataSet : Validation data and Train\n",
    "x_train, x_valid, y_train, y_valid= train_test_split(\n",
    "    x_train, y_train, test_size=.05, random_state=42,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Transform the images to equal sizes to feed in CNN\n",
    "#for using the CNN, we need to change The size of images ( The size of images must be the same)\n",
    "im_rows=112\n",
    "im_cols=92\n",
    "batch_size=512\n",
    "im_shape=(im_rows, im_cols, 1)\n",
    "\n",
    "#change the size of images\n",
    "x_train = x_train.reshape(x_train.shape[0], *im_shape)\n",
    "x_test = x_test.reshape(x_test.shape[0], *im_shape)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], *im_shape)\n",
    "\n",
    "print('x_train shape: {}'.format(y_train.shape[0]))\n",
    "print('x_test shape: {}'.format(y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5:   Build a CNN model that has 3 main layers:\n",
    "     #*    Convolutional Layer\n",
    "     #*    Pooling Layer\n",
    "     #*    Fully Connected Layer\n",
    "#filters= the depth of output image or kernels\n",
    "\n",
    "cnn_model= Sequential([\n",
    "    Conv2D(filters=36, kernel_size=7, activation='relu', input_shape= im_shape),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Conv2D(filters=54, kernel_size=5, activation='relu', input_shape= im_shape),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(2024, activation='relu'),\n",
    "     Dropout(0.5),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    #20 is the number of outputs\n",
    "    Dense(20, activation='softmax')  \n",
    "])\n",
    "\n",
    "cnn_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',#'categorical_crossentropy',\n",
    "    optimizer=Adam(lr=0.0001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the model's parameters\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6:   Train the model\n",
    "history=cnn_model.fit(\n",
    "    np.array(x_train), np.array(y_train), batch_size=512,\n",
    "    epochs=150, verbose=2,\n",
    "    validation_data=(np.array(x_valid),np.array(y_valid)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the test data\n",
    "scor = cnn_model.evaluate( np.array(x_test),  np.array(y_test), verbose=0)\n",
    "\n",
    "print('test los {:.4f}'.format(scor[0]))\n",
    "print('test acc {:.4f}'.format(scor[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7:   Plot the result\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step8:   Iterate the model until the accuracy is above 90%\n",
    "#First run showed ~ %92 accurancy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
